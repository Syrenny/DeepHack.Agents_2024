{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0890963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./2404.15626v1.An_Electromagnetism_Inspired_Method_for_Estimating_In_Grasp_Torque_from_Visuotactile_Sensors.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "search = arxiv.Search(\n",
    "    query = \"Attention is all you need\",\n",
    "    max_results = 10,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate, \n",
    "    sort_order=arxiv.SortOrder.Descending\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "# `results` is a generator; you can iterate over its elements one by one...\n",
    "for r in client.results(search):\n",
    "    print(r.download_pdf())\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"assets/arxiv_paper.pdf\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792d767",
   "metadata": {},
   "source": [
    "## Инициализация модели\n",
    "Теперь инициализируем модель GigaChat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f584c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.txt\", 'r', encoding='utf-8') as file:\n",
    "    credentials = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7f08a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.gigachat import GigaChat\n",
    "llm = GigaChat(credentials=credentials, scope=\"GIGACHAT_API_CORP\", verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "loader = TextLoader(\"assets/arxiv_paper.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(f\"Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f26e74",
   "metadata": {},
   "source": [
    "После нарезки мы получили 91 документ частями книги.\n",
    "\n",
    "## Создание базы данных эмбеддингов\n",
    "\n",
    "Эмбеддинг это векторное представление текста, которое может быть использовано для определения смысловой близости текстов. Векторная база данных хранит тексты и соответствующие им эмбеддинги, а также умеет выполнять поиск по ним. Для работы с базой данных мы создаем объект GigaChatEmbeddings и передаем его в базу данных Chroma.\n",
    "\n",
    "> Обратите внимание, что сервис для вычисления эмбеддингов может тарифицироваться отдельно от стоимости модели GigaChat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a34068ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
    "\n",
    "embeddings = GigaChatEmbeddings(\n",
    "    credentials=credentials, scope=\"GIGACHAT_API_CORP\", verify_ssl_certs=False\n",
    ")\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    client_settings=Settings(anonymized_telemetry=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa3321",
   "metadata": {},
   "source": [
    "## Поиск по базе данных\n",
    "\n",
    "Теперь можно обратиться к базе данных и попросить найти документы, которые с наибольшей вероятностью содержат ответ на наш вопрос.\n",
    "\n",
    "По-умолчанию база данных возвращает 4 наиболее релевантных документа. Этот параметр можно изменить в зависимости от решаемой задачи и типа документов.\n",
    "\n",
    "Видно, что первый же документ содержит внутри себя часть книги с ответом на наш вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d347d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = db.similarity_search(question, k=4)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b78573a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ение (fork) открытой библиотеки LangСhain на Python. Её главная цель — облегчить жизнь разработчику. Библиотека состоит из большого количества различных компонентов, которые позвол ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"... {str(docs[0])[620:800]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7426b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "propmpt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate(\n",
    "            #             prompt = \"\"\"Сгенерируй от {dataset_size_min} до {dataset_size_max} синонимов для слова \"{subject}\".\n",
    "            # Результат верни в формате JSON списка без каких либо пояснений, например, [\"синоним1\", \"синоним2\", \"синоним3\", \"синоним4\"].\n",
    "            # Не дублируй фразы.\"\"\"\n",
    "            prompt=load_prompt(\"lc://prompts/synonyms/synonyms_generation.yaml\")\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0e3f1",
   "metadata": {},
   "source": [
    "## QnA цепочка\n",
    "\n",
    "Теперь мы создадим цепочку QnA, которая специально предназначена для ответов на вопросы по документам. В качестве аргументов есть передается языковая модель и ретривер (база данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a9afeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c4e1fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['context', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]), llm=GigaChat(credentials='YmZlNGMwYWQtM2E0ZS00NzQ3LWIzMzQtZWYxN2NjNTYxODEyOmIyMjkxZTI2LTg4NjktNDc1Yy05NjE5LTg2NzUxNzc3MWZmYg==', scope='GIGACHAT_API_CORP', verify_ssl_certs=False, _client=<gigachat.GigaChat object at 0x7f82e5000940>)), document_variable_name='context') retriever=VectorStoreRetriever(tags=['Chroma', 'GigaChatEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f82e5090a30>)\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a078b",
   "metadata": {},
   "source": [
    "Наконец можно задать вопрос нашей цепочке и получить правильный ответ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17d9caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Syrenny/GigaHack/Syrenny/giga_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Какой Loss использует Yolov8?',\n",
       " 'result': 'Я не знаю ответа на этот вопрос.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6efaf6",
   "metadata": {},
   "source": [
    "Несколько дополнительных вопросов для проверки работоспособности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "325a9a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Расскажи про тимлида Сбера',\n",
       " 'result': 'Извините, но у меня нет информации о конкретном тимлиде Сбера. Могу рассказать вам о том, что такое тимлид и какие у него обязанности. Тимлид - это лидер команды, который отвечает за управление командой, ее развитие и достижение поставленных целей. Он координирует работу членов команды, помогает им решать возникающие проблемы, поддерживает мотивацию и вовлеченность. Кроме того, тимлид также участвует в принятии решений, связанных с проектами, и помогает команде в достижении общих целей.'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": \"Расскажи про тимлида Сбера\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aab1c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Основные особенности Yolov8',\n",
       " 'result': 'YOLOv8 имеет несколько особенностей, которые отличают его от других версий YOLO. Во-первых, он использует новую архитектуру, которая сочетает в себе модули FAN и PAN. Это позволяет ему лучше захватывать особенности на разных масштабах и разрешениях, что важно для точного обнаружения объектов разного размера и формы. Кроме того, YOLOv8 превосходит YOLOv5 по нескольким параметрам, включая более высокую метрику mAP и меньшее количество выбросов при измерении против RF100. Он также превосходит YOLOv5 для каждого RF100 категории.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": \"Основные особенности Yolov8\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ce70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\"NLP\", \"RAG\", \"ChatBot\", \"LLM\", \"Speech Recognition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0b61902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import os\n",
    "import json\n",
    "\n",
    "def download_from_arxiv(key_word, max_results=10, destination_path=\"assets/arxiv/\", saved_list_path=\"assets/arxiv/papers.json\"):\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query = str(key_word),\n",
    "        max_results = max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate, \n",
    "        sort_order=arxiv.SortOrder.Descending\n",
    "    )\n",
    "    # Проверка существования файла с сохраненным списком скачанных arXiv ID\n",
    "    if os.path.exists(saved_list_path):\n",
    "        with open(saved_list_path, \"r\") as f:\n",
    "            downloaded_arxiv_ids = json.load(f)\n",
    "    else:\n",
    "        downloaded_arxiv_ids = []\n",
    "    \n",
    "    for result in client.results(search):\n",
    "        # Проверка наличия статьи в списке уже скачанных\n",
    "        if result.entry_id.split(\"/\")[-1] in downloaded_arxiv_ids:\n",
    "            print(f\"Статья {result.entry_id} уже скачана и пропущена.\")\n",
    "            continue\n",
    "        \n",
    "        # Скачивание PDF-файла статьи\n",
    "        pdf_path = result.download_pdf(dirpath=destination_path)\n",
    "        if pdf_path:\n",
    "            print(f\"Статья {result.entry_id} успешно скачана и сохранена в {pdf_path}\")\n",
    "            # Добавление arXiv ID в список скачанных\n",
    "            downloaded_arxiv_ids.append(result.entry_id.split(\"/\")[-1])\n",
    "    # Сохранение списка скачанных arXiv ID в файл JSON\n",
    "    with open(saved_list_path, \"w\") as f:\n",
    "        json.dump(downloaded_arxiv_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a20a184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статья http://arxiv.org/abs/2404.15488v1 уже скачана и пропущена.\n",
      "Статья http://arxiv.org/abs/2404.14043v1 уже скачана и пропущена.\n"
     ]
    }
   ],
   "source": [
    "# Пример использования функции\n",
    "download_from_arxiv(\"RAG\", max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de5dbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_files(directory):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "94d857c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets/arxiv/2404.14043v1.LLMs_Know_What_They_Need__Leveraging_a_Missing_Information_Guided_Framework_to_Empower_Retrieval_Augmented_Generation.pdf\n",
      "assets/arxiv/2404.15488v1.IryoNLP_at_MEDIQA_CORR_2024__Tackling_the_Medical_Error_Detection___Correction_Task_On_the_Shoulders_of_Medical_Agents.pdf\n"
     ]
    }
   ],
   "source": [
    "# Пример использования функции\n",
    "directory = \"assets/arxiv/\"\n",
    "pdf_files = get_pdf_files(directory)\n",
    "for pdf_file in pdf_files:\n",
    "    print(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "98707a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts count: 32\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"assets/arxiv/\")\n",
    "# loader = UnstructuredPDFLoader(pdf_files)\n",
    "# loader = PyPDFLoader(pdf_files)\n",
    "docs = loader.load()\n",
    "\n",
    "split_docs = CharacterTextSplitter(chunk_size=5000, chunk_overlap=1000).split_documents(\n",
    "    docs\n",
    ")\n",
    "print(f\"Parts count: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54a4babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Syrenny/GigaHack/Syrenny/giga_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===\n",
      "This paper presents the MIGRES framework for improving Retrieval-Augmented Generation (RAG) in Large Language Models (LLMs) by leveraging missing information to generate targeted queries and filter out irrelevant content. The framework also includes an information extraction capability of LLMs. Extensive experiments demonstrate the superiority of the proposed method. Additionally, the MedReAct'N'MedReFlex framework is presented as a multi-agent system for medical error detection and correction in clinical notes. The system incorporates four specialized medical agents and five evaluators for comprehensive feedback. The framework optimizes its semantic search engine and achieves the ninth rank in a competition with an aggregation score of 0.581.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "giga = GigaChat(credentials=credentials, scope=\"GIGACHAT_API_CORP\", verify_ssl_certs=False)\n",
    "chain = load_summarize_chain(giga, chain_type=\"map_reduce\")\n",
    "res = chain.run(split_docs)\n",
    "\n",
    "print(\"\\n\\n===\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cf63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giga_kernel",
   "language": "python",
   "name": "giga_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
