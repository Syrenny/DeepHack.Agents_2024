{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "\n",
    "# Base api query url\n",
    "base_url = \"http://export.arxiv.org/api/query?\"\n",
    "\n",
    "# Search parameters\n",
    "query_params = {\n",
    "    'search_query': \"all:rag\",\n",
    "    'start': 0,  # retreive the first 5 results\n",
    "    'max_results': 5,\n",
    "    'sortBy': \"submittedDate\",\n",
    "    'sortOrder': \"descending\"\n",
    "}\n",
    "query = urllib.parse.urlencode(query_params)\n",
    "\n",
    "# perform a GET request using the base_url and query\n",
    "response = requests.get(base_url + query)\n",
    "\n",
    "# parse the response using feedparser\n",
    "feed = feedparser.parse(response.text)\n",
    "\n",
    "# print out feed information\n",
    "print(\"Feed title: %s\" % feed.feed.title)\n",
    "print(\"Feed last updated: %s\" % feed.feed.updated)\n",
    "\n",
    "# print opensearch metadata\n",
    "print(\"totalResults for this query: %s\" % feed.feed.opensearch_totalresults)\n",
    "print(\"itemsPerPage for this query: %s\" % feed.feed.opensearch_itemsperpage)\n",
    "print(\"startIndex for this query: %s\" % feed.feed.opensearch_startindex)\n",
    "\n",
    "# Run through each entry, and print out information\n",
    "for entry in feed.entries:\n",
    "    print(\"e-print metadata\")\n",
    "    print(\"arxiv-id: %s\" % entry.id.split(\"/abs/\")[-1])\n",
    "    print(\"Published: %s\" % entry.published)\n",
    "    print(\"Title:  %s\" % entry.title)\n",
    "\n",
    "    # Authors\n",
    "    authors = entry.authors\n",
    "    if authors:\n",
    "        print(\"Authors:  %s\" % \",\".join(author.name for author in authors))\n",
    "\n",
    "    # get the links to the abs page and pdf for this e-print\n",
    "    for link in entry.links:\n",
    "        if link.rel == \"alternate\":\n",
    "            print(\"abs page link: %s\" % link.href)\n",
    "        elif link.title == \"pdf\":\n",
    "            print(\"pdf link: %s\" % link.href)\n",
    "\n",
    "    # The journal reference, comments and primary_category sections live under\n",
    "    # the arxiv namespace\n",
    "    journal_ref = getattr(entry, 'arxiv_journal_ref', 'No journal ref found')\n",
    "    print(\"Journal reference: %s\" % journal_ref)\n",
    "\n",
    "    comment = getattr(entry, 'arxiv_comment', 'No comment found')\n",
    "    print(\"Comments: %s\" % comment)\n",
    "\n",
    "    primary_category = entry.tags[0][\"term\"]\n",
    "    print(\"Primary Category: %s\" % primary_category)\n",
    "\n",
    "    all_categories = [t[\"term\"] for t in entry.tags]\n",
    "    print(\"All Categories: %s\" % (\", \").join(all_categories))\n",
    "\n",
    "    print(\"Abstract: %s\" % entry.summary)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75adde4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Electromagnetism-Inspired Method for Estimating In-Grasp Torque from Visuotactile Sensors\n",
      "Optimizing OOD Detection in Molecular Graphs: A Novel Approach with Diffusion Models\n",
      "A new framework of high-order unfitted finite element methods using ALE maps for moving-domain problems\n",
      "Characterizing the Age of Information with Multiple Coexisting Data Streams\n",
      "FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search\n",
      "Layer Ensemble Averaging for Improving Memristor-Based Artificial Neural Network Performance\n",
      "A Dynamic Kernel Prior Model for Unsupervised Blind Image Super-Resolution\n",
      "Neuromorphic Shack-Hartmann wave normal sensing\n",
      "Neural Operator induced Gaussian Process framework for probabilistic solution of parametric partial differential equations\n",
      "DPO: Differential reinforcement learning with application to optimal configuration search\n",
      "['An Electromagnetism-Inspired Method for Estimating In-Grasp Torque from Visuotactile Sensors', 'Optimizing OOD Detection in Molecular Graphs: A Novel Approach with Diffusion Models', 'A new framework of high-order unfitted finite element methods using ALE maps for moving-domain problems', 'Characterizing the Age of Information with Multiple Coexisting Data Streams', 'FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search', 'Layer Ensemble Averaging for Improving Memristor-Based Artificial Neural Network Performance', 'A Dynamic Kernel Prior Model for Unsupervised Blind Image Super-Resolution', 'Neuromorphic Shack-Hartmann wave normal sensing', 'Neural Operator induced Gaussian Process framework for probabilistic solution of parametric partial differential equations', 'DPO: Differential reinforcement learning with application to optimal configuration search']\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "search = arxiv.Search(\n",
    "  query = \"Attention is all you need\",\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "# `results` is a generator; you can iterate over its elements one by one...\n",
    "for r in client.results(search):\n",
    "  print(r.title)\n",
    "# ...or exhaust it into a list. Careful: this is slow for large results sets.\n",
    "all_results = list(results)\n",
    "print([r.title for r in all_results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a73fca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|#########################################################################################################| 2/2 [00:00<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "import json\n",
    "\n",
    "\n",
    "# Load HTML\n",
    "links = [\"https://habr.com/ru/companies/sberbank/articles/805337/\",\n",
    "         \"https://habr.com/ru/feed/\"]\n",
    "\n",
    "loader = AsyncHtmlLoader(links)\n",
    "html = loader.load()\n",
    "\n",
    "bs_transformer = BeautifulSoupTransformer()\n",
    "docs_transformed = bs_transformer.transform_documents(html, tags_to_extract=[\"span\",\"p\"])\n",
    "\n",
    "result = {}\n",
    "for i in range(len(links)):\n",
    "    result[links[i]] = docs_transformed[i].page_content\n",
    "    \n",
    "f = open(\"assets/pages_content.json\",\"w\")\n",
    "f.write(json.dumps(result))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdd34c",
   "metadata": {},
   "source": [
    "## Инициализация модели\n",
    "Теперь инициализируем модель GigaChat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d4b2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.txt\", 'r', encoding='utf-8') as file:\n",
    "    credentials = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb7018a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.gigachat import GigaChat\n",
    "llm = GigaChat(credentials=credentials, scope=\"GIGACHAT_API_CORP\", verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e209b",
   "metadata": {},
   "source": [
    "Для проверки спросим у модели вопрос про цвет плаща без какого-либо контекста. Возможно, она и так будет давать ожидаемый ответ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "252525b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Syrenny/GigaHack/Syrenny/giga_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'YOLOv8 использует несколько видов потерь для обучения модели. Однако, основной вид потери, который используется в большинстве случаев, это Cross-Entropy Loss (CEL). \\n\\nCross-Entropy Loss (CEL) - это фу'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "question = \"Какой Loss использует Yolov8?\"\n",
    "llm([HumanMessage(content=question)]).content[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757b326c",
   "metadata": {},
   "source": [
    "Видим, что модель не отвечает так, как нам хотелось бы, поэтому применим RAG-подход.\n",
    "\n",
    "## Подготовка документа\n",
    "\n",
    "Для работы с документом нам нужно разделить его на части. Для этого используем `TextLoader` для загрузки книги и `RecursiveCharacterTextSplitter`, чтобы разделить текст на приблизительно равные куски в ~1000 символов с перекрытием в ~200 символов. Этот тип сплиттера сам выбирает каким способом следует оптимально разделять документ (по абзацам, по предложениям и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2877920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 20\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "loader = TextLoader(\"assets/habr_paper.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(f\"Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5a5bf",
   "metadata": {},
   "source": [
    "После нарезки мы получили 91 документ частями книги.\n",
    "\n",
    "## Создание базы данных эмбеддингов\n",
    "\n",
    "Эмбеддинг это векторное представление текста, которое может быть использовано для определения смысловой близости текстов. Векторная база данных хранит тексты и соответствующие им эмбеддинги, а также умеет выполнять поиск по ним. Для работы с базой данных мы создаем объект GigaChatEmbeddings и передаем его в базу данных Chroma.\n",
    "\n",
    "> Обратите внимание, что сервис для вычисления эмбеддингов может тарифицироваться отдельно от стоимости модели GigaChat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2208ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
    "\n",
    "embeddings = GigaChatEmbeddings(\n",
    "    credentials=credentials, scope=\"GIGACHAT_API_CORP\", verify_ssl_certs=False\n",
    ")\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    client_settings=Settings(anonymized_telemetry=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53a370",
   "metadata": {},
   "source": [
    "## Поиск по базе данных\n",
    "\n",
    "Теперь можно обратиться к базе данных и попросить найти документы, которые с наибольшей вероятностью содержат ответ на наш вопрос.\n",
    "\n",
    "По-умолчанию база данных возвращает 4 наиболее релевантных документа. Этот параметр можно изменить в зависимости от решаемой задачи и типа документов.\n",
    "\n",
    "Видно, что первый же документ содержит внутри себя часть книги с ответом на наш вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e164df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = db.similarity_search(question, k=4)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ad5a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ение (fork) открытой библиотеки LangСhain на Python. Её главная цель — облегчить жизнь разработчику. Библиотека состоит из большого количества различных компонентов, которые позвол ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"... {str(docs[0])[620:800]} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e898a",
   "metadata": {},
   "source": [
    "## QnA цепочка\n",
    "\n",
    "Теперь мы создадим цепочку QnA, которая специально предназначена для ответов на вопросы по документам. В качестве аргументов есть передается языковая модель и ретривер (база данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2af12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c3cb071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['context', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]), llm=GigaChat(credentials='YmZlNGMwYWQtM2E0ZS00NzQ3LWIzMzQtZWYxN2NjNTYxODEyOmIyMjkxZTI2LTg4NjktNDc1Yy05NjE5LTg2NzUxNzc3MWZmYg==', scope='GIGACHAT_API_CORP', verify_ssl_certs=False, _client=<gigachat.GigaChat object at 0x7f82e5000940>)), document_variable_name='context') retriever=VectorStoreRetriever(tags=['Chroma', 'GigaChatEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f82e5090a30>)\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e87b55",
   "metadata": {},
   "source": [
    "Наконец можно задать вопрос нашей цепочке и получить правильный ответ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77c67231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Syrenny/GigaHack/Syrenny/giga_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Какой Loss использует Yolov8?',\n",
       " 'result': 'Я не знаю ответа на этот вопрос.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9197a6a",
   "metadata": {},
   "source": [
    "Несколько дополнительных вопросов для проверки работоспособности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9b53768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Сформируй запрос в поисковую систему для поиска нформации про RAG',\n",
       " 'result': 'Извините, но я не могу выполнить ваш запрос. Пожалуйста, уточните свой вопрос или попробуйте еще раз.'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": \"Сформируй запрос в поисковую систему для поиска нформации про RAG\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e995d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Основные особенности Yolov8',\n",
       " 'result': 'YOLOv8 имеет несколько особенностей, которые отличают его от других версий YOLO. Во-первых, он использует новую архитектуру, которая сочетает в себе модули FAN и PAN. Это позволяет ему лучше захватывать особенности на разных масштабах и разрешениях, что важно для точного обнаружения объектов разного размера и формы. Кроме того, YOLOv8 превосходит YOLOv5 по нескольким параметрам, включая более высокую метрику mAP и меньшее количество выбросов при измерении против RF100. Он также превосходит YOLOv5 для каждого RF100 категории.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": \"Основные особенности Yolov8\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adc3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giga_kernel",
   "language": "python",
   "name": "giga_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
